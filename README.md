GxEScanR: An R Package to Detect GxE Interactions in a Genome-wide
Association Study
================

<!-- ![](files/page1.png) -->

<!-- ![](files/test.png) -->

*Version: 1.0*  
*October 2018*

##### Developed by:

  - John Morrison, M.S. (<JMorr@usc.edu>)  
  - Andre E. Kim, Ph.D. (<Andreeki@usc.edu>)  
  - Jim Gauderman, Ph.D. (<JimG@usc.edu>)

##### Acknowledgements

Supported in part by NCI grants PO1-CA196569 and RO1-CA201407 and NIEHS
grant P30-ES007048.

##### Reference, software

1.  Morrison, J, Kim AE, Gauderman J. GxEScanR: An R package to detect
    GxE interactions in a genomewide association study, Version 1.0.
    University of Southern California, Los Angeles; October, 2018.
    <http://Github.com/USCBiostats/GxEScanR>

##### References, methods

2.  Gauderman J, Mukherjee B, Aschard H, Hsu L, Lewinger JP, Patel C,
    Witte J, Amos C, Tai C, Conti D, Torgerson D, Lee S, Chatterjee N.
    Update on the State of the Science for Analytical Methods for
    Gene-Environment Interactions. Am J Epidemiol 186:762-70, 2017.

3.  Gauderman J, Zhang P, Morrison J, Lewinger JP. Finding Novel Genes
    by Testing GxE Interactions in a Genomewide Association Study.
    Genetic Epidemiology, 37:603-613, 2013.  
    <br>

*Thank you for using GxEScanR for your GxE interation analysis.*  
<br> *We would appreciate hearing about any errors you might find or
comments you might have to improve the program. Please e-mail
questions/comments to Jim Gauderman.*

-----

# General Description

GxEScanR is an R package that performs a genomewide scan for
gene-environment (GxE) interaction for a disease trait. The program
implements the traditional test of GxE interaction in a case-control
sample, the case-only test of GxE interaction, the 2-degree-of-freedom
(df) joint test of G and GxE, and efficient 2-step methods for tests of
either GxE or joint G & GxE<sup>1</sup>. As a byproduct of the available
tests, GxEScanR also produces results for the standard marginal G scan,
i.e. the standard test of each SNP conducted in a GWAS.

The ‘environment’ factor E in the GxE scans may be either binary or
continuous and can be an exogenous exposure variable (e.g., sunlight,
air pollution), personal exposure (e.g., smoking, dietary fat), or other
personal characteristic (e.g., sex, age, candidate gene). GxEScanR will
test GxE interaction with measured and/or imputed SNPs on autosomal
chromosomes and will control the family-wise error rate (FWER) at a
user-defined level (e.g. 5%).

GxEScanR utilizes C++ (via RCpp) to improve computational speed. The
program also reads binary-formatted imputed SNP files which further
improves speed. A companion program,
[BinaryDosage](http://Github.com/USCBiostats/BinaryDosage), is available
to convert VCF or IMPUTE2 imputed SNP files into the binary format
required by GxEScanR. The BinaryDosage program should be used before
using GxEScanR.

### Functions

  - **GetBinaryDosageInfo** - Create R List containing BDose file
    attributes (required for *GxEScan*)
  - **GxEScan** - Run GWAS/GWIS (See below)

### Program Outputs

GxEScanR produces a single text-formatted output file that includes the
SNP identifier and the effect estimate and test statistic for all of the
tests described below.

##### Output statistics

  - **BetaG/zG**: Marginal G (CC\_DG) association  
  - **BetaGxE/zGxE**: GxE (CC\_GxE) interaction  
  - **Chi2df**: Joint G, GxE (CC\_2df) association  
  - **Beta\_Case/z\_Case**: Case-only G-E association (Case\_GE)  
  - **Beta\_Control/z\_Control**: Control-only G-E association
    (Cntl\_GE)  
  - **Beta\_GE/z\_GE**: Overall G-E association in cases and controls
    combined (CC\_GE)

These statistics can be used to generate QQplots and/or Manhattan plots
using your favorite R program or other software. A companion R package
that will generate QQplots and Manhattan plots for all of the tests
generated by GxEScanR is currently under construction.

With additional R coding (at this point on your own) the above
statistics can be used to generate the CC\_3df test (see Section 2.5) or
any of the 2-step procedures (see Section 2.6). A companion R Package
that will read GxEScanR output and generate the 3-df and 2-step tests
described above is currently under construction.

### Installation

1.  Install the [devtools](https://github.com/hadley/devtools) package
2.  Install the [GxEScanR](https://github.com/USCbiostats/GxEScanR)
    package directly from the USCbiostats repository on GitHub:

<!-- end list -->

``` r
library(devtools)
install_github("USCbiostats/GxEScanR")

library(GxEScanR)
```

### Example

Use example BDose and dummy covariate file provided in GitHub
repository.

##### Run GxEScan

``` r
library(GxEScanR)

# Read dummy phenotype file
cov <- read.table("example_pheno.txt", header = T)
bdose <- GxEScanR::GetBinaryDosageInfo("example.bdose")
GxEScan(cov, bdose, "example_results.out")
```

##### Results - Output File

``` r
library(qqman)
library(kableExtra)

results <- read.table("example_results.out", stringsAsFactors = F, header = T)

# Calculate P values from Z statistics
results$zP <- 2 * pnorm(-abs(results$zG))
results$zGxEP <- 2 * pnorm(-abs(results$zGxE))

# View results data.frame
kable(head(results)) %>% kable_styling(bootstrap_options = "condensed", full_width = F, 
    position = "left", font_size = 11) %>% scroll_box(width = "800px", height = "350px")
```

<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:350px; overflow-x: scroll; width:800px; ">

<table class="table table-condensed" style="font-size: 11px; width: auto !important; ">

<thead>

<tr>

<th style="text-align:right;">

CHR

</th>

<th style="text-align:left;">

SNP

</th>

<th style="text-align:right;">

BP

</th>

<th style="text-align:left;">

A1

</th>

<th style="text-align:left;">

A2

</th>

<th style="text-align:right;">

Cases

</th>

<th style="text-align:right;">

Controls

</th>

<th style="text-align:right;">

BetaG

</th>

<th style="text-align:right;">

zG

</th>

<th style="text-align:right;">

BetaGxE

</th>

<th style="text-align:right;">

zGxE

</th>

<th style="text-align:right;">

Chi2df

</th>

<th style="text-align:left;">

GEModel

</th>

<th style="text-align:right;">

Beta\_GE

</th>

<th style="text-align:right;">

z\_GE

</th>

<th style="text-align:left;">

OnlyModel

</th>

<th style="text-align:right;">

Beta\_Case

</th>

<th style="text-align:right;">

z\_Case

</th>

<th style="text-align:right;">

Beta\_Ctrl

</th>

<th style="text-align:right;">

z\_Ctrl

</th>

<th style="text-align:right;">

zP

</th>

<th style="text-align:right;">

zGxEP

</th>

</tr>

</thead>

<tbody>

<tr>

<td style="text-align:right;">

1

</td>

<td style="text-align:left;">

1:10576\_C\_A

</td>

<td style="text-align:right;">

10576

</td>

<td style="text-align:left;">

C

</td>

<td style="text-align:left;">

A

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

\-0.0005734

</td>

<td style="text-align:right;">

\-0.0047828

</td>

<td style="text-align:right;">

0.4791060

</td>

<td style="text-align:right;">

1.834320

</td>

<td style="text-align:right;">

3.364740

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.5466980

</td>

<td style="text-align:right;">

2.025500

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.2451120

</td>

<td style="text-align:right;">

0.6644790

</td>

<td style="text-align:right;">

0.806754

</td>

<td style="text-align:right;">

1.9129100

</td>

<td style="text-align:right;">

0.9961839

</td>

<td style="text-align:right;">

0.0666065

</td>

</tr>

<tr>

<td style="text-align:right;">

1

</td>

<td style="text-align:left;">

1:10943\_A\_T

</td>

<td style="text-align:right;">

10943

</td>

<td style="text-align:left;">

A

</td>

<td style="text-align:left;">

T

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

0.0359020

</td>

<td style="text-align:right;">

0.5002750

</td>

<td style="text-align:right;">

0.1446030

</td>

<td style="text-align:right;">

0.927959

</td>

<td style="text-align:right;">

1.111430

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.0641318

</td>

<td style="text-align:right;">

0.394248

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.0067235

</td>

<td style="text-align:right;">

0.0304801

</td>

<td style="text-align:right;">

\-0.190633

</td>

<td style="text-align:right;">

\-0.5606990

</td>

<td style="text-align:right;">

0.6168815

</td>

<td style="text-align:right;">

0.3534288

</td>

</tr>

<tr>

<td style="text-align:right;">

1

</td>

<td style="text-align:left;">

1:11309\_G\_T

</td>

<td style="text-align:right;">

11309

</td>

<td style="text-align:left;">

G

</td>

<td style="text-align:left;">

T

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

\-0.8692020

</td>

<td style="text-align:right;">

\-7.9112700

</td>

<td style="text-align:right;">

\-0.6240100

</td>

<td style="text-align:right;">

\-2.581100

</td>

<td style="text-align:right;">

65.350300

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

\-0.1849520

</td>

<td style="text-align:right;">

\-0.878347

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

\-1.3987400

</td>

<td style="text-align:right;">

\-4.0161000

</td>

<td style="text-align:right;">

\-16.827200

</td>

<td style="text-align:right;">

\-0.0184147

</td>

<td style="text-align:right;">

0.0000000

</td>

<td style="text-align:right;">

0.0098486

</td>

</tr>

<tr>

<td style="text-align:right;">

1

</td>

<td style="text-align:left;">

1:10614\_G\_C

</td>

<td style="text-align:right;">

10614

</td>

<td style="text-align:left;">

G

</td>

<td style="text-align:left;">

C

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

\-0.2075120

</td>

<td style="text-align:right;">

\-1.7158800

</td>

<td style="text-align:right;">

\-0.1004060

</td>

<td style="text-align:right;">

\-0.378719

</td>

<td style="text-align:right;">

3.073350

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.1768990

</td>

<td style="text-align:right;">

0.710527

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.1188290

</td>

<td style="text-align:right;">

0.3597920

</td>

<td style="text-align:right;">

0.137381

</td>

<td style="text-align:right;">

0.2846310

</td>

<td style="text-align:right;">

0.0861840

</td>

<td style="text-align:right;">

0.7048965

</td>

</tr>

<tr>

<td style="text-align:right;">

1

</td>

<td style="text-align:left;">

1:11396\_G\_T

</td>

<td style="text-align:right;">

11396

</td>

<td style="text-align:left;">

G

</td>

<td style="text-align:left;">

T

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

\-0.0694808

</td>

<td style="text-align:right;">

\-0.6439030

</td>

<td style="text-align:right;">

0.0494758

</td>

<td style="text-align:right;">

0.210464

</td>

<td style="text-align:right;">

0.459181

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.1188810

</td>

<td style="text-align:right;">

0.509855

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.2536370

</td>

<td style="text-align:right;">

0.8125970

</td>

<td style="text-align:right;">

\-0.400742

</td>

<td style="text-align:right;">

\-0.7105080

</td>

<td style="text-align:right;">

0.5196383

</td>

<td style="text-align:right;">

0.8333055

</td>

</tr>

<tr>

<td style="text-align:right;">

1

</td>

<td style="text-align:left;">

1:11877\_A\_T

</td>

<td style="text-align:right;">

11877

</td>

<td style="text-align:left;">

A

</td>

<td style="text-align:left;">

T

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

1000

</td>

<td style="text-align:right;">

0.0078403

</td>

<td style="text-align:right;">

0.1007370

</td>

<td style="text-align:right;">

0.3087200

</td>

<td style="text-align:right;">

1.823920

</td>

<td style="text-align:right;">

3.337190

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.0243699

</td>

<td style="text-align:right;">

0.142368

</td>

<td style="text-align:left;">

H

</td>

<td style="text-align:right;">

0.1147340

</td>

<td style="text-align:right;">

0.5062920

</td>

<td style="text-align:right;">

\-0.120045

</td>

<td style="text-align:right;">

\-0.3379250

</td>

<td style="text-align:right;">

0.9197592

</td>

<td style="text-align:right;">

0.0681642

</td>

</tr>

</tbody>

</table>

</div>

##### Results - Plots

``` r
qq(results$zP, main = "Marginal G QQ Plot")
```

![](README_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

``` r
manhattan(results, chr = "CHR", bp = "BP", p = "zP", snp = "SNP", main = "Marginal G Results", 
    highlight = "1:11309_G_T", annotatePval = 5e-08)
```

![](README_files/figure-gfm/unnamed-chunk-4-2.png)<!-- -->

``` r

qq(results$zGxEP, main = "GxE QQ Plot")
```

![](README_files/figure-gfm/unnamed-chunk-4-3.png)<!-- -->

``` r
manhattan(results, chr = "CHR", bp = "BP", p = "zGxEP", main = "GxE Results")
```

![](README_files/figure-gfm/unnamed-chunk-4-4.png)<!-- -->

-----

# Methods

## 1\. Notation

We assume the data are derived from a case-control study in which cases
and controls are unrelated (i.e. not a family-based design). The
following notation will be used throughout this documentation:

**D**: Disease status (1=case, 0=control)

**E**: Environmental factor of interest, which can be binary or
continuous, e.g.  
    • Indicator of exposure (e.g. 1=Exposed, 0=Unexposed)  
    • Indicator of sex (e.g. 1=Female, 0=Male)  
    • Quantitative exposure (e.g. pack-years of tobacco smoking)  
    • Personal factor (e.g. age)  
    • Candidate locus genotype (e.g. 0, 1, or 2 variant alleles)

**C**: A set of adjustment covariates, which can be binary and/or
continuous variables (optional)

**D**, **E**, and **C** must be in a single R data frame that also
includes a unique subject identifier. This identifier is used to link
the **D**, **E**, and **C** data to the subject’s corresponding SNP
data.

**G**: Imputed genotype “dosage” at one of M SNPs being scanned for GxE
interaction. Only SNPs on autosomal chromosomes can be analyzed. We
assume that the goal is to analyze the M SNPs to identify one or more
disease susceptibility loci (DSL). We assume the underlying genotype for
each SNP is biallelic, with possible genotype 0 (two major alleles), 1
(heterozygous), or 2 (two minor alleles). For each SNP, the imputed
dosage is assumed to be a value between 0 and 2 representing the
expected number of minor alleles. In addition to dosage, the imputation
program may also provide genotype probabilities p0, p1, p2, the
probabilities of genotype 0, 1, or 2, respectively. The BinaryDosage
program (see Introduction) will read the available data from a VCF- or
IMPUTE2-formatted file and generate dosages (and possibly genotype
probabilities) in the binary format required by GxEScanR.

## 2\. Models: Disease Trait

***<u>2.1 Marginal</u>*** **Test (CC\_DG association)**: In a
case-control study, the marginal effect of a SNP
(![G](https://latex.codecogs.com/png.latex?G "G")) on disease
(![D](https://latex.codecogs.com/png.latex?D "D")) with possible
adjustment for covariates (![C](https://latex.codecogs.com/png.latex?C
"C")) is typically measured by the genetic odds ratio
![OR\_G](https://latex.codecogs.com/png.latex?OR_G "OR_G"), which can be
obtained as
![exp(\\lambda\_G)](https://latex.codecogs.com/png.latex?exp%28%5Clambda_G%29
"exp(\\lambda_G)") from a logistic regression model of the form:

<center>

1.  ![Logit(Pr(D=1|G)) = \\lambda\_0 + \\lambda\_GG +
    \\boldsymbol{\\lambda\_CC}](https://latex.codecogs.com/png.latex?Logit%28Pr%28D%3D1%7CG%29%29%20%3D%20%5Clambda_0%20%2B%20%5Clambda_GG%20%2B%20%5Cboldsymbol%7B%5Clambda_CC%7D
    "Logit(Pr(D=1|G)) = \\lambda_0 + \\lambda_GG + \\boldsymbol{\\lambda_CC}")

</center>

A standard GWAS of marginal effects is conducted by testing the null
hypothesis
![\\lambda\_G=0](https://latex.codecogs.com/png.latex?%5Clambda_G%3D0
"\\lambda_G=0") for each of M SNPs in turn, with corresponding test
statistic ![S\_DG](https://latex.codecogs.com/png.latex?S_DG "S_DG").
Note that because ![G](https://latex.codecogs.com/png.latex?G "G") is
scaled from 0 to 2,
![exp(\\lambda\_G)](https://latex.codecogs.com/png.latex?exp%28%5Clambda_G%29
"exp(\\lambda_G)") represents the odds ratio per increase of one allele,
for example the OR comparing a heterozygote to a homozygous normal. One
typically adopts a strict significance level (e.g. 5 x 10-8) to preserve
the family-wise error rate (FWER).  
<br>

***<u>2.2 Interaction Test</u>*** **(CC\_GxE association)**: In a second
genomewide scan, one could augment the model in Equation 1 to test each
SNP in turn for GxE interaction using the model:

<center>

2.  ![Logit(Pr(D=1|G)) = \\beta\_0 + \\beta\_GG + \\beta\_EE +
    \\beta\_{GxE}GxE +
    \\boldsymbol{\\beta\_CC}](https://latex.codecogs.com/png.latex?Logit%28Pr%28D%3D1%7CG%29%29%20%3D%20%5Cbeta_0%20%2B%20%5Cbeta_GG%20%2B%20%5Cbeta_EE%20%2B%20%5Cbeta_%7BGxE%7DGxE%20%2B%20%5Cboldsymbol%7B%5Cbeta_CC%7D
    "Logit(Pr(D=1|G)) = \\beta_0 + \\beta_GG + \\beta_EE + \\beta_{GxE}GxE + \\boldsymbol{\\beta_CC}")

</center>

A genomewide interaction scan is based on testing the null hypothesis
![\\beta\_{GxE}
= 0](https://latex.codecogs.com/png.latex?%5Cbeta_%7BGxE%7D%20%3D%200
"\\beta_{GxE} = 0") using test statistic
![S\_{GxE}](https://latex.codecogs.com/png.latex?S_%7BGxE%7D "S_{GxE}")
for each SNP in turn, with strict significance level to preserve the
FWER. The quantity
![OR\_{GxE}=exp(\\beta\_{GxE})](https://latex.codecogs.com/png.latex?OR_%7BGxE%7D%3Dexp%28%5Cbeta_%7BGxE%7D%29
"OR_{GxE}=exp(\\beta_{GxE})") is the interaction odds ratio, e.g. the
genetic effect in exposed individuals relative to the genetic effect in
unexposed (![OR\_{G|E=1} /
OR\_{G|E=0}](https://latex.codecogs.com/png.latex?OR_%7BG%7CE%3D1%7D%20%2F%20OR_%7BG%7CE%3D0%7D
"OR_{G|E=1} / OR_{G|E=0}")).  
<br>

***<u>2.3 Interaction Test</u>*** **(Case\_GE)**: A more powerful test
of GxE interaction can be obtained using a case-only analysis, in which
“GE” association is tested between
![E](https://latex.codecogs.com/png.latex?E "E") and each SNP in
affected individuals<sup>2</sup>. GxEScanR models
![G](https://latex.codecogs.com/png.latex?G "G") as a function of
![E](https://latex.codecogs.com/png.latex?E "E"), based on the
polytomous logistic model:

<center>

3.  ![Logit(Pr(G=g | E, D=1)) = \\gamma\_0 + \\gamma\_1 +
    \\gamma\_E(g)(E) + \\boldsymbol{\\gamma\_CC} \\;\\;\\;\\;\\;\\; g
    = 0,1,2](https://latex.codecogs.com/png.latex?Logit%28Pr%28G%3Dg%20%7C%20E%2C%20D%3D1%29%29%20%3D%20%5Cgamma_0%20%2B%20%5Cgamma_1%20%2B%20%5Cgamma_E%28g%29%28E%29%20%2B%20%5Cboldsymbol%7B%5Cgamma_CC%7D%20%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%20g%20%3D%200%2C1%2C2
    "Logit(Pr(G=g | E, D=1)) = \\gamma_0 + \\gamma_1 + \\gamma_E(g)(E) + \\boldsymbol{\\gamma_CC} \\;\\;\\;\\;\\;\\; g = 0,1,2")

</center>

If ![G](https://latex.codecogs.com/png.latex?G "G") and
![E](https://latex.codecogs.com/png.latex?E "E") are independent in the
population, the quantity
![exp(\\gamma\_E)](https://latex.codecogs.com/png.latex?exp%28%5Cgamma_E%29
"exp(\\gamma_E)") is a consistent estimator of the GxE relative risk
ratio<sup>2</sup> and the Wald test of ![H0: \\gamma\_E
= 0](https://latex.codecogs.com/png.latex?H0%3A%20%5Cgamma_E%20%3D%200
"H0: \\gamma_E = 0") is asymptotically equivalent to testing ![H0:
\\beta\_{GxE}
= 0](https://latex.codecogs.com/png.latex?H0%3A%20%5Cbeta_%7BGxE%7D%20%3D%200
"H0: \\beta_{GxE} = 0") in Model 2. Although a case-only analysis can be
substantially more powerful than a case-control analysis<sup>3</sup>, it
depends critically on the assumption of population-level G-E
independence. For some SNPs, there may not be sufficient sample size
within each genotypic group to estimate both
![\\gamma\_0](https://latex.codecogs.com/png.latex?%5Cgamma_0
"\\gamma_0") and
![\\gamma\_1](https://latex.codecogs.com/png.latex?%5Cgamma_1
"\\gamma_1"), so that estimates and tests cannot be obtained. GxEScanR
will detect this situation and for such a SNP will fit an alternative
allelic model of the form

<center>

4.  ![Logit(Pr(A | E, D=1)) = \\gamma\_0 + \\gamma\_E(g)(E) +
    \\boldsymbol{\\gamma\_CC}](https://latex.codecogs.com/png.latex?Logit%28Pr%28A%20%7C%20E%2C%20D%3D1%29%29%20%3D%20%5Cgamma_0%20%2B%20%5Cgamma_E%28g%29%28E%29%20%2B%20%5Cboldsymbol%7B%5Cgamma_CC%7D
    "Logit(Pr(A | E, D=1)) = \\gamma_0 + \\gamma_E(g)(E) + \\boldsymbol{\\gamma_CC}")

</center>

where an allele A can have value 0 or 1 and the SNP genotype is
constructed from two such alleles. GxEScanR forms the corresponding
likelihood for G assuming Hardy Weinberg equilibrium. SNPs for which the
model in Eq 3 does not converge often will converge using the model in
Eq 4.

For imputed SNP data, GxEScanR forms the likelihood contribution for
each subject based on Model 3 (if genotype probabilities are available)
or Model 4 (if allele dosage values are available).

GxEScanR also generates results from applying Model 3 or 4 to the subset
of Controls Only (Cntl\_GE, based on unaffected subjects). While this
does not provide a test of GxE interaction, it can provide useful
results for examining whether there is general G-E association that
might be due to factors other than GxE interaction.  
<br>

***<u>2.4 Joint G, GxE Test </u>*** **(CC\_2df)**: Kraft et
al.<sup>4</sup> demonstrated that a test of joint null hypothesis
![\\beta\_G=\\beta\_{GxE}=0](https://latex.codecogs.com/png.latex?%5Cbeta_G%3D%5Cbeta_%7BGxE%7D%3D0
"\\beta_G=\\beta_{GxE}=0") based on the model in Eq 2 can sometimes
provide greater power to detect a DSL than either the marginal DG test
or the case-control GxE test alone. This test has 2 degrees of freedom
(2 df) provided G and E are each coded using a single variable. Note
that the joint test evaluates a fundamentally different null hypothesis
than the GxE-alone tests and in practice will produce different SNPs on
the top lists.  
<br>

***<u>2.5 Joint G, GxE, G-E Correlation </u>*** **(CC\_3df)**: GxE
interaction can induce a correlation between G and E in the combined
case-control sample. This information can be used to advantage to
construct the 2-step test proposed by Murcray et al.<sup>5</sup> and
described below in Section 2.6.2. It can also be used in conjunction
with the 2 df joint test of G and GxE (Section 2.6) to potentially
capture more GxE information in a single test statistic. We rely on the
independence of the G-E correlation test of
![\\delta\_G](https://latex.codecogs.com/png.latex?%5Cdelta_G
"\\delta_G") (CC\_GE, see Equation 5) and the 2 df test (CC\_2df) to
form a new statistic, T3, that is the sum of the two corresponding
chi-squared statistics. Under the joint null hypothesis that
![\\beta\_G=\\beta\_{GxE}=\\beta\_G=0](https://latex.codecogs.com/png.latex?%5Cbeta_G%3D%5Cbeta_%7BGxE%7D%3D%5Cbeta_G%3D0
"\\beta_G=\\beta_{GxE}=\\beta_G=0"), T3 has a chi-squared distribution
with 3 degrees of freedom.  
<br>

***<u>2.6 Two-Step Procedures </u>*** : Several two-step methods have
been proposed to conduct a genomewide GxE scan<sup>5</sup>. All of these
procedures generally provide greater power than a case-control GxE
analysis while preserving the Type I error rate. Some 2-step methods can
achieve greater power than a case-only analysis.

A key requirement for any of the two-step methods is independence of the
Step-1 screening and Step-2 testing statistics. The 2-step methods
described below all have this independence, and the component statistics
required to form the corresponding tests are all generated by GxEScanR.
The Step 2 test for each of the procedures below can be evaluated for
significance based on ‘subset-testing’ or ‘weighted hypothesis testing’
(see Section 3). A separate R package (under construction) will generate
results for both the subset and weighted approaches for all of the
procedures below. <br>

  - ***<u> 2.6.1 2-Step, screening on D-G association</u>*** **(DG |
    GxE)**: Kooperberg and LeBlanc<sup>6</sup> proposed a 2-step
    procedure that uses the marginal DG association statistic
    ![S\_{DG}](https://latex.codecogs.com/png.latex?S_%7BDG%7D "S_{DG}")
    to screen SNPs at Step-1 significance level
    ![\\alpha\_1](https://latex.codecogs.com/png.latex?%5Calpha_1
    "\\alpha_1"). They proposed testing the subset m \<\< M SNPs that
    pass the Step-1 screen using Step-2 test statistic
    ![S\_{GxE}](https://latex.codecogs.com/png.latex?S_%7BGxE%7D
    "S_{GxE}"), with Bonferroni-corrected significance level
    ![\\alpha/m](https://latex.codecogs.com/png.latex?%5Calpha%2Fm
    "\\alpha/m") to preserve the FWER. We denote their method DG|GxE.

  - ***<u> 2.6.2 2-Step, screening on G-E correlation</u>*** **(GE |
    GxE)**: Murcray et al.<sup>5</sup> demonstrated that in the presence
    of GxE interaction, there is an induced correlation between G and E
    in the combined case-control sample. In other words, based on the
    model

<center>

5.  ![Logit(Pr(G=g | E, D=1)) = \\delta\_0 + \\delta\_1 + \\delta\_E
    (g)(E) + \\boldsymbol{\\delta\_CC} \\;\\;\\;\\;\\;\\; g
    = 0,1,2](https://latex.codecogs.com/png.latex?Logit%28Pr%28G%3Dg%20%7C%20E%2C%20D%3D1%29%29%20%3D%20%5Cdelta_0%20%2B%20%5Cdelta_1%20%2B%20%5Cdelta_E%20%28g%29%28E%29%20%2B%20%5Cboldsymbol%7B%5Cdelta_CC%7D%20%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%20g%20%3D%200%2C1%2C2
    "Logit(Pr(G=g | E, D=1)) = \\delta_0 + \\delta_1 + \\delta_E (g)(E) + \\boldsymbol{\\delta_CC} \\;\\;\\;\\;\\;\\; g = 0,1,2")

</center>

  - applied to the full sample of cases and controls, one can typically
    expect ![\\delta\_E
    \\ne 0](https://latex.codecogs.com/png.latex?%5Cdelta_E%20%5Cne%200
    "\\delta_E \\ne 0") in the presence of GxE interaction. They
    proposed using test statistic
    ![S\_{GE}](https://latex.codecogs.com/png.latex?S_%7BGE%7D "S_{GE}")
    (labelled CC\_GE) of ![H0: \\delta\_E
    = 0](https://latex.codecogs.com/png.latex?H0%3A%20%5Cdelta_E%20%3D%200
    "H0: \\delta_E = 0") as a Step 1 screen at significance level
    ![\\alpha\_1](https://latex.codecogs.com/png.latex?%5Calpha_1
    "\\alpha_1"). They proposed testing the subset m \<\< M SNPs that
    pass the screen using Step-2 test statistic
    ![S\_{GxE}](https://latex.codecogs.com/png.latex?S_%7BGxE%7D
    "S_{GxE}") at significance level
    ![\\alpha/m](https://latex.codecogs.com/png.latex?%5Calpha%2Fm
    "\\alpha/m"). GxEScanR implements this ‘subset-testing’ approach as
    well as a modification that uses ‘weighted hypothesis testing’ in
    Step 2 (see 3). The use of the model in Eq 5 rather than the
    case-only model in Eq 3 preserves the necessary independence between
    Steps 1 and 2. As for a case-only analysis, the modified model with
    form shown in Eq 4 will be applied to a SNP for which the model in
    Eq 5 does not converge or if a single dosage value is provided based
    on imputation.

  - ***<u> 2.6.3 2-Step, screening on DG and GE</u>*** **(EDGE)**: This
    approach, developed by Gauderman et al.<sup>10</sup>, provides a
    more efficient screen by using all available surrogate information
    in a single Step-1 screening test. The name EDGE derives from gE+Dg
    screening followed by GxE testing. Specifically, for each of the M
    SNPs, one computes ![S\_{DG+GE} = S\_{DG} +
    S\_{GE}](https://latex.codecogs.com/png.latex?S_%7BDG%2BGE%7D%20%3D%20S_%7BDG%7D%20%2B%20S_%7BGE%7D
    "S_{DG+GE} = S_{DG} + S_{GE}"), (labelled CC\_DGGE) i.e. the sum of
    the DG and GE screening statistics. Under the null hypothesis of no
    GxE interaction,
    ![S\_{DG}](https://latex.codecogs.com/png.latex?S_%7BDG%7D "S_{DG}")
    and ![S\_{GE}](https://latex.codecogs.com/png.latex?S_%7BGE%7D
    "S_{GE}") are independent<sup>11</sup>, and each follows a central
    chi-squared distribution with 1 degree of freedom (df) under their
    respective null hypotheses. Thus,
    ![S\_{DG+GE}](https://latex.codecogs.com/png.latex?S_%7BDG%2BGE%7D
    "S_{DG+GE}") follows a central chi-squared distribution with 2 df.
    The Step-2 test is based on
    ![S\_{GxE}](https://latex.codecogs.com/png.latex?S_%7BGxE%7D
    "S_{GxE}"). We advocate using ‘weighted hypothesis testing’ in Step
    2 rather than ‘subset testing’, although both approaches are
    supported in GxEScanR. We have demonstrated that this method
    typically provides greater power than any of the above 2-step
    methods, particularly for a gene with a weak marginal (DG)
    association<sup>10</sup>.

## 3\. Step-2 Hypothesis Testing Approaches

GxEScanR generates the necessary statistics to facilitate two approaches
to hypothesis testing in Step 2 for all of the two-step methods.

<u>a. Subset Testing</u>: Test only a subset m \<\< M SNPs that have ![p
\< \\alpha\_1](https://latex.codecogs.com/png.latex?p%20%3C%20%5Calpha_1
"p \< \\alpha_1") from the Step 1 screen, with Step 2 significance level
![\\alpha/m](https://latex.codecogs.com/png.latex?%5Calpha%2Fm
"\\alpha/m") (i.e. a Bonferroni correction for the number of SNPs that
pass Step 1). Here the analyst must specify
![\\alpha\_1](https://latex.codecogs.com/png.latex?%5Calpha_1
"\\alpha_1"). A larger value of
![\\alpha\_1](https://latex.codecogs.com/png.latex?%5Calpha_1
"\\alpha_1") will increase the chance of passing a DSL into Step 2, but
at the cost of also increasing the number of unassociated SNPs that pass
into Step 2. A lower value of
![alpha\_1](https://latex.codecogs.com/png.latex?alpha_1 "alpha_1")
leads to lower ![m](https://latex.codecogs.com/png.latex?m "m") and thus
greater power in Step 2, but at the potential cost of screening out a
DSL. The optimal choice of
![\\alpha\_1](https://latex.codecogs.com/png.latex?%5Calpha_1
"\\alpha_1") depends strongly on M but also on other underlying
parameters (e.g. minor allele frequency of a DSL, exposure frequency,
magnitude of an interaction, etc.). As a general rule, we have found
that setting
![\\alpha\_1](https://latex.codecogs.com/png.latex?%5Calpha_1
"\\alpha_1") so that between m=25 and m=200 SNPs pass into Step 2 is
near optimal for many models. For example, if M=1 million, setting
![\\alpha\_1](https://latex.codecogs.com/png.latex?%5Calpha_1
"\\alpha_1") to 0.0001 would yield approximately m=100 SNPs to be tested
in Step 2.

<u>b. Weighted Hypothesis Testing</u>: Rather than restrict Step-2
testing to a subset of the SNPs, one can test all M SNPs using a
weighted significance level in Step 2 based on the ordered p-values from
Step 1 and an initial bin size B<sup>12</sup>. Specifically, the B most
significant (lowest p-value) SNPs based on Step 1 are evaluated in Step
2 at significance level
![(\\alpha/2)/B](https://latex.codecogs.com/png.latex?%28%5Calpha%2F2%29%2FB
"(\\alpha/2)/B"), the next 2B SNPs are evaluated at
![(\\alpha/4)/(2B)](https://latex.codecogs.com/png.latex?%28%5Calpha%2F4%29%2F%282B%29
"(\\alpha/4)/(2B)"), the next 4B at
![(\\alpha/8)/(4B)](https://latex.codecogs.com/png.latex?%28%5Calpha%2F8%29%2F%284B%29
"(\\alpha/8)/(4B)"), etc. As shown by Ionita-Laza et al.<sup>12</sup>,
this guarantees that the overall significance level for the entire
procedure does not exceed
![\\alpha](https://latex.codecogs.com/png.latex?%5Calpha "\\alpha").
They recommended setting B to 5. When B=5 the top 5 SNPs from Step 1 are
tested in Step 2 at significance level 0.005, the next 10 at 0.00125,
etc. Note that with weighted testing the top SNPs from Step 1 are tested
at a more liberal (less strict) significance threshold than the standard
5 x 10-8 level required in an exhaustive scan of all M SNPs using
standard methods. However, the majority of SNPs will be tested at a
significance level that is more stringent than 5x10-8. This indicates
the importance of using an efficient Step-1 screening approach with
strong likelihood of highly ranking any SNP with a true interaction. As
an example, across many simulation scenarios for a disease outcome, we
have found the Step-1 screen of the EDGxE method tends to rank true
signals higher than the corresponding Step-1 screens of alternative
2-step methods.

<br><br><br><br>

# References

<div id="refs" class="references">

<div id="ref-Gauderman2017">

1\. Gauderman, W. J. *et al.* Update on the State of the Science for
Analytical Methods for Gene-Environment Interactions. *American Journal
of Epidemiology* **186,** 762–770 (2017).

</div>

<div id="ref-Piegorsch1994">

2\. Piegorsch, W. W., Weinberg, C. R. & Taylor, J. A. Non-hierarchical
logistic models and caseonlydesigns for assessing susceptibility in
population-based case-control studies. *Statistical Medicine* **13,**
153–162 (1994).

</div>

<div id="ref-Yang1997">

3\. Yang, Q., Khoury, M. J. & Flanders, W. D. Sample size requirements
in case-only designs to detect gene-environment interaction. *American
Journal of Epidemiology* (1997).
doi:[10.1093/oxfordjournals.aje.a009346](https://doi.org/10.1093/oxfordjournals.aje.a009346)

</div>

<div id="ref-Kraft2007a">

4\. Kraft, P., Yen, Y. C., Stram, D. O., Morrison, J. & Gauderman, W. J.
Exploiting gene-environment interaction to detect genetic associations.
*Human Heredity* **63,** 111–119 (2007).

</div>

<div id="ref-Murcray2009">

5\. Murcray, C. E., Lewinger, J. P. & Gauderman, W. J. Gene-environment
interaction in genome-wide association studies. *American Journal of
Epidemiology* **169,** 219–226 (2009).

</div>

<div id="ref-Leblanc2010">

6\. Kooperberg, C. & LeBlanc, M. Increasing the power of identifying
gene x gene interactions in genome-wide association studies. *Genetic
Epidemiology* **32,** 255–263 (2008).

</div>

<div id="ref-Li2009">

7\. Li, D. & Conti, D. V. Detecting gene-environment interactions using
a combined case-only and case-control approach. *American Journal of
Epidemiology* **169,** 497–504 (2009).

</div>

<div id="ref-Murcray2011">

8\. Murcray, C. E., Lewinger, J. P., Conti, D. V., Thomas, D. C. &
Gauderman, W. J. Sample size requirements to detect gene-environment
interactions in genome-wide association studies. *Genetic Epidemiology*
(2011). doi:[10.1002/gepi.20569](https://doi.org/10.1002/gepi.20569)

</div>

<div id="ref-Hsu2012">

9\. Hsu, L. *et al.* Powerful cocktail methods for detecting genome-wide
gene-environment interaction. *Genetic epidemiology* **36,** 183–194
(2012).

</div>

<div id="ref-Gauderman2013">

10\. Gauderman, W. J., Zhang, P., Morrison, J. L. & Lewinger, J. P.
Finding Novel Genes by Testing G × E Interactions in a Genome-Wide
Association Study. *Genetic Epidemiology* **37,** 603–613 (2013).

</div>

<div id="ref-Dai2012">

11\. Dai, J. Y., Kooperberg, C., Leblanc, M. & Prentice, R. L. Two-stage
testing procedures with independent filtering for genome-wide
gene-environment interaction. *Biometrika* **99,** 929–944 (2012).

</div>

<div id="ref-Ionita-Laza2007">

12\. Ionita-Laza, I., McQueen, M. B., Laird, N. M. & Lange, C.
Genomewide Weighted Hypothesis Testing in Family-Based Association
Studies, with an Application to a 100K Scan. *American Journal of Human
Genetics* **81,** 607–614 (2007).

</div>

</div>
